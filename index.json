[
  {
    "authors": [
      "An-Chieh Cheng\\*",
      "***Chieh Hubert Lin***\\*",
      "Da-Cheng Juan",
      "Wei Wei",
      "Min Sun"
    ],
    "categories": null,
    "content": "",
    "date": 1543161600,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1543161600,
    "objectID": "a0ffbeb61ab9e2fb01232354df1af4a8",
    "permalink": "https://hubert0527.github.io/publication/instanas/",
    "publishdate": "2018-11-26T00:00:00+08:00",
    "relpermalink": "/publication/instanas/",
    "section": "publication",
    "summary": "Neural Architecture Search (NAS) aims at finding one ''single'' architecture that achieves the best accuracy for a given task such as image recognition.In this paper, we study the instance-level variation,and demonstrate that instance-awareness is an important yet currently missing component of NAS. Based on this observation, we propose InstaNAS for searching toward instance-level architectures;the controller is trained to search and form a ''distribution of architectures'' instead of a single final architecture. Then during the inference phase, the controller selects an architecture from the distribution, tailored for each unseen image to achieve both high accuracy and short latency. The experimental results show that InstaNAS reduces the inference latency without compromising classification accuracy. On average, InstaNAS achieves 48.9% latency reduction on CIFAR-10 and 40.2% latency reduction on CIFAR-100 with respect to MobileNetV2 architecture.",
    "tags": [
      "Neural Architecture Search",
      "Reinforcement Learning"
    ],
    "title": "InstaNAS: Instance-aware Neural Architecture Search",
    "type": "publication"
  },
  {
    "authors": [
      "***Chieh Hubert Lin***",
      "Chia-Che Chang",
      "Yu-Sheng Chen",
      "Da-Cheng Juan",
      "Wei Wei",
      "Hwann-Tzong Chen"
    ],
    "categories": null,
    "content": "",
    "date": 1538064000,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1538064000,
    "objectID": "d8c6aac979aef9df3b828ff2c01a9726",
    "permalink": "https://hubert0527.github.io/publication/coco-gan/",
    "publishdate": "2018-09-28T00:00:00+08:00",
    "relpermalink": "/publication/coco-gan/",
    "section": "publication",
    "summary": "Recent advancements on Generative Adversarial Network (GAN) have inspired a wide range of works that generate synthetic images. However, current processes have to generate an entire image at once, and therefore resolutions are limited by memory or computational constraints. In this work, we propose __**CO**__nditional __**CO**__ordinate GAN (COCO-GAN), which generates a specific patch of an image conditioned on a spatial position rather than the entire image at a time. The generated patches are later combined together to form a globally coherent full-image. We show that the images generated by COCO-GAN can achieve competitive quality to state-of-the-art models, and the generated patches are locally smooth between consecutive neighbors without any post-processing. COCO-GAN unveils the potential of generating high-quality images under conditional coordinated generation and creates a new research direction on spatial separability. Owing to the spatially separable property, COCO-GAN is highly parallelable and enables the next step toward large field-of-view data generation with a built-in divide-and-conquer strategy.",
    "tags": [
      "Generative Adversarial Networks",
      "Computer Vision"
    ],
    "title": "COCO-GAN: Conditional Coordinate Generative Adversarial Network",
    "type": "publication"
  },
  {
    "authors": [
      "Chia-Che Chang\\*",
      "***Chieh Hubert Lin***\\*",
      "Che-Rung Lee",
      "Da-Cheng Juan",
      "Wei Wei",
      "Hwann-Tzong Chen"
    ],
    "categories": null,
    "content": "",
    "date": 1531324800,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1531324800,
    "objectID": "e8a16ab860ee349baed03dad82a4e738",
    "permalink": "https://hubert0527.github.io/publication/began-cs/",
    "publishdate": "2018-07-12T00:00:00+08:00",
    "relpermalink": "/publication/began-cs/",
    "section": "publication",
    "summary": "Generative adversarial networks (GANs) often suffer from unpredictable mode-collapsing during training. We study the issue of mode collapse of Boundary Equilibrium Generative Adversarial Network (BEGAN), which is one of the state-of-the-art generative models. Despite its potential of generating high-quality images, we find that BEGAN tends to collapse at some modes after a period of training. We propose a new model, called **BEGAN with a Constrained Space** (BEGAN-CS), which includes a latent-space constraint in the loss function. We show that BEGAN-CS can significantly improve training stability and suppress mode collapse without either increasing the model complexity or degrading the image quality. Further, we visualize the distribution of latent vectors to elucidate the effect of latent-space constraint. The experimental results show that our method has additional advantages of being able to train on small datasets and to generate images similar to a given real image yet with variations of designated attributes on-the-fly.",
    "tags": [
      "Generative Adversarial Networks",
      "Computer Vision"
    ],
    "title": "Escaping from Collapsing Modes in a Constrained Space",
    "type": "publication"
  },
  {
    "authors": null,
    "categories": null,
    "content": "",
    "date": 1515686400,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1515686400,
    "objectID": "e667844c3c988f963344079503225823",
    "permalink": "https://hubert0527.github.io/project/human2anime/",
    "publishdate": "2018-01-12T00:00:00+08:00",
    "relpermalink": "/project/human2anime/",
    "section": "project",
    "summary": "Transforming human face to anime girl face with CycleGAN.",
    "tags": [
      "Generative Adversarial Networks",
      "For Fun"
    ],
    "title": "Human2anime",
    "type": "project"
  },
  {
    "authors": null,
    "categories": null,
    "content": "",
    "date": 1497456000,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1497456000,
    "objectID": "93c5b696a3d898f31461244547650d8e",
    "permalink": "https://hubert0527.github.io/project/quora-question-pair/",
    "publishdate": "2017-06-15T00:00:00+08:00",
    "relpermalink": "/project/quora-question-pair/",
    "section": "project",
    "summary": "Discriminate if the demonstrated question pair is duplicated questions or not. We won a competition bronze medal and a kernel silver medal in this competition.",
    "tags": [
      "NLP",
      "Kaggle"
    ],
    "title": "Kaggle - Quora Question Pair Competition",
    "type": "project"
  }
]